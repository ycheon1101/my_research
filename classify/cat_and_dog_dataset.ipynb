{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# from torchvision import datasets\n",
    "# ToTensor = range[0,1]\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    return img\n",
    "\n",
    "class CatAndDog(Dataset):\n",
    "    def __init__(self,csv_file, img_dir, transform=None, target_transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file, names = ['image', 'labels'])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform= transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    # The number of sample dataset\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    # Call and return samples based on idx\n",
    "    def __getitem__(self, idx):\n",
    "        # iloc for row = idx, col = 0\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        # label = self.annotations.iloc[idx, 1]\n",
    "        label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# test\n",
    "\n",
    "# csv_file = './cat_dog.csv'\n",
    "# img_dir = './cat_dog/image/'\n",
    "# dataset = CatAndDog(csv_file, img_dir)\n",
    "# print(\"Dataset size:\", len(dataset))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_num = 1\n",
    "\n",
    "# cat_dog_data_set = CatAndDog(\n",
    "#     img_dir='./cat_dog/image/',\n",
    "#     # pixel range [0, 1]\n",
    "#     transform=ToTensor(),\n",
    "#     # one-hot encoding(convert categorical data into numerical data)\n",
    "#     target_transform=(lambda y: torch.zeros(class_num, d_type=torch.float).scatter_(0, torch.float).scatter_(0, torch.tensor(label), value=1))\n",
    "# )\n",
    "\n",
    "# sample_idx = 0  \n",
    "# print(cat_dog_data_set[sample_idx])\n",
    "# image, label = cat_dog_data_set[sample_idx]\n",
    "\n",
    "# print(\"Label (one-hot encoded):\", label)\n",
    "# print(\"Image shape:\", image.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
